{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6MHrsbVnh9J4"
      },
      "source": [
        "## This notebook will be focusing on deploying the model to Hugging Face spaces as a demo application.\n",
        "\n",
        "## Deployed model link: https://huggingface.co/spaces/purplelord2003/Trash_Object_Detector\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lJCAhbp0iIQS"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "\n",
        "# Create demos folder\n",
        "trash_detector_demo_path = Path(\"demos/trash_detector/\")\n",
        "\n",
        "if trash_detector_demo_path.exists():\n",
        "  print(\"Directory already exists\")\n",
        "\n",
        "else:\n",
        "  trash_detector_demo_path.mkdir(parents=True,\n",
        "                                 exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "examples_path = trash_detector_demo_path / \"examples\"\n",
        "examples_path.mkdir(parents=True,\n",
        "                    exist_ok=True)"
      ],
      "metadata": {
        "id": "Tz-Be6n2yWCd"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create model.py script for demo app"
      ],
      "metadata": {
        "id": "SIrmEtxL06Ay"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "wFJk5cgus4_n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae75a321-db3b-4a9b-9a61-a60ce40e921f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing demos/trash_detector/model.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile demos/trash_detector/model.py\n",
        "import torch\n",
        "from torchvision import models\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "\n",
        "def create_fasterrcnn_model():\n",
        "  model_weights = models.detection.FasterRCNN_ResNet50_FPN_V2_Weights.DEFAULT\n",
        "  model = models.detection.fasterrcnn_resnet50_fpn_v2(weights=model_weights)\n",
        "  transforms = model_weights.transforms()\n",
        "  num_classes = 61\n",
        "  in_features = 1024\n",
        "  model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
        "  return model, transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ysWXnH8Vw3Ul",
        "outputId": "b0e59dfa-cbd1-4fc9-face-5879d124d56f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.1.0+cu121'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# Check versions of dependencies for requirements.txt\n",
        "import torch\n",
        "torch.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "DVPrsFVXxgfq",
        "outputId": "04ca8bf1-424d-43bf-df03-4e741d51b15c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0.16.0+cu121'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "import torchvision\n",
        "torchvision.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create requirements.txt"
      ],
      "metadata": {
        "id": "DWCWBm8Y0-D5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_kn73D4xmqg",
        "outputId": "d454a9fb-e233-4b6f-c551-d778e5b12be6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing demos/trash_detector/requirements.txt\n"
          ]
        }
      ],
      "source": [
        "%%writefile demos/trash_detector/requirements.txt\n",
        "torch==2.1.0\n",
        "torchvision==0.16.0\n",
        "gradio==3.41.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "itx4HNFE7hZj",
        "outputId": "d10fbe53-4645-47c2-976a-66c40c56c2d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-02-06 10:22:02--  https://github.com/purplelord2003/Object-Detection-Model/raw/main/Demo%20preparation/fasterrcnn_resnet50_5_epochs_unaugmented.pth\n",
            "Resolving github.com (github.com)... 140.82.112.4\n",
            "Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://media.githubusercontent.com/media/purplelord2003/Object-Detection-Model/main/Demo%20preparation/fasterrcnn_resnet50_5_epochs_unaugmented.pth [following]\n",
            "--2024-02-06 10:22:03--  https://media.githubusercontent.com/media/purplelord2003/Object-Detection-Model/main/Demo%20preparation/fasterrcnn_resnet50_5_epochs_unaugmented.pth\n",
            "Resolving media.githubusercontent.com (media.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to media.githubusercontent.com (media.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 174626786 (167M) [application/octet-stream]\n",
            "Saving to: â€˜demos/trash_detector/fasterrcnn_resnet50_5_epochs_unaugmented.pthâ€™\n",
            "\n",
            "fasterrcnn_resnet50 100%[===================>] 166.54M   180MB/s    in 0.9s    \n",
            "\n",
            "2024-02-06 10:22:12 (180 MB/s) - â€˜demos/trash_detector/fasterrcnn_resnet50_5_epochs_unaugmented.pthâ€™ saved [174626786/174626786]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Get best model saved state dict determined in previous notebook\n",
        "!wget -P demos/trash_detector/ https://github.com/purplelord2003/Object-Detection-Model/raw/main/Demo%20preparation/fasterrcnn_resnet50_5_epochs_unaugmented.pth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dsoyvwblps4y",
        "outputId": "f188637f-bf9f-443f-d415-baa80c34b324"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-02-06 10:22:12--  https://github.com/purplelord2003/Object-Detection-Model/raw/main/Demo%20preparation/class_names.txt\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/purplelord2003/Object-Detection-Model/main/Demo%20preparation/class_names.txt [following]\n",
            "--2024-02-06 10:22:13--  https://raw.githubusercontent.com/purplelord2003/Object-Detection-Model/main/Demo%20preparation/class_names.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 859 [text/plain]\n",
            "Saving to: â€˜demos/trash_detector/class_names.txtâ€™\n",
            "\n",
            "class_names.txt     100%[===================>]     859  --.-KB/s    in 0s      \n",
            "\n",
            "2024-02-06 10:22:13 (68.5 MB/s) - â€˜demos/trash_detector/class_names.txtâ€™ saved [859/859]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Get class names txt file\n",
        "!wget -P demos/trash_detector/ https://github.com/purplelord2003/Object-Detection-Model/raw/main/Demo%20preparation/class_names.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "CFOPgZiDqMhB"
      },
      "outputs": [],
      "source": [
        "# Get all the class names\n",
        "with open(\"demos/trash_detector/class_names.txt\", \"r\") as f: # reading them in from class_names.txt\n",
        "  class_names = [class_name.strip() for class_name in f.readlines()]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bNWVDudWwbV6",
        "outputId": "63801988-3ac6-4db0-d410-2197ae4d9b67"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Aluminium foil',\n",
              " 'Battery',\n",
              " 'Aluminium blister pack',\n",
              " 'Carded blister pack',\n",
              " 'Other plastic bottle',\n",
              " 'Clear plastic bottle',\n",
              " 'Glass bottle',\n",
              " 'Plastic bottle cap',\n",
              " 'Metal bottle cap',\n",
              " 'Broken glass',\n",
              " 'Food Can',\n",
              " 'Aerosol',\n",
              " 'Drink can',\n",
              " 'Toilet tube',\n",
              " 'Other carton',\n",
              " 'Egg carton',\n",
              " 'Drink carton',\n",
              " 'Corrugated carton',\n",
              " 'Meal carton',\n",
              " 'Pizza box',\n",
              " 'Paper cup',\n",
              " 'Disposable plastic cup',\n",
              " 'Foam cup',\n",
              " 'Glass cup',\n",
              " 'Other plastic cup',\n",
              " 'Food waste',\n",
              " 'Glass jar',\n",
              " 'Plastic lid',\n",
              " 'Metal lid',\n",
              " 'Other plastic',\n",
              " 'Magazine paper',\n",
              " 'Tissues',\n",
              " 'Wrapping paper',\n",
              " 'Normal paper',\n",
              " 'Paper bag',\n",
              " 'Plastified paper bag',\n",
              " 'Plastic film',\n",
              " 'Six pack rings',\n",
              " 'Garbage bag',\n",
              " 'Other plastic wrapper',\n",
              " 'Single-use carrier bag',\n",
              " 'Polypropylene bag',\n",
              " 'Crisp packet',\n",
              " 'Spread tub',\n",
              " 'Tupperware',\n",
              " 'Disposable food container',\n",
              " 'Foam food container',\n",
              " 'Other plastic container',\n",
              " 'Plastic gloves',\n",
              " 'Plastic utensils',\n",
              " 'Pop tab',\n",
              " 'Rope & strings',\n",
              " 'Scrap metal',\n",
              " 'Shoe',\n",
              " 'Squeezable tube',\n",
              " 'Plastic straw',\n",
              " 'Paper straw',\n",
              " 'Styrofoam piece',\n",
              " 'Unlabeled litter',\n",
              " 'Cigarette']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Write app.py"
      ],
      "metadata": {
        "id": "liHJr4Sh1U1D"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DboQnAeHyTQF",
        "outputId": "a09c0c66-470b-4ea4-e056-1592580ada0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing demos/trash_detector/app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile demos/trash_detector/app.py\n",
        "\n",
        "import gradio as gr\n",
        "import os\n",
        "import torch\n",
        "import torchvision\n",
        "from model import create_fasterrcnn_model\n",
        "\n",
        "# Set up class names\n",
        "with open(\"class_names.txt\", \"r\") as f: # reading them in from class_names.txt\n",
        "  class_names = [class_name.strip() for class_name in f.readlines()]\n",
        "\n",
        "# Create model and transforms\n",
        "model, transforms = create_fasterrcnn_model()\n",
        "\n",
        "# Load saved weights\n",
        "model.load_state_dict(\n",
        "    torch.load(f=\"fasterrcnn_resnet50_5_epochs_unaugmented.pth\",\n",
        "               map_location=torch.device(\"cpu\")) # Hugging Face spaces free tier gives cpu\n",
        ")\n",
        "\n",
        "# Prediction function\n",
        "def predict(img: gr.Image=None, iou_threshold: float=0.5, score_threshold: float=0.5):\n",
        "\n",
        "  # Get dimensions of the image\n",
        "  width, height = img.size[0], img.size[1]\n",
        "\n",
        "  # Resize if too small\n",
        "  if width < 500 or height < 500:\n",
        "    scaling = 500 / min(width, height)\n",
        "    img = img.resize((int(width*scaling), int(height*scaling)))\n",
        "    width, height = img.size[0], img.size[1]\n",
        "  average = (width + height) / 2 # Help us to determine size of labels later\n",
        "\n",
        "  # Transform the target image\n",
        "  img = transforms(img)\n",
        "\n",
        "  # Evaluation mode and inference mode\n",
        "  model.eval()\n",
        "  with torch.inference_mode():\n",
        "    predictions = model(img.unsqueeze(dim=0))\n",
        "    pred = predictions[0]\n",
        "\n",
        "  img = torch.tensor(img*255, dtype=torch.uint8)\n",
        "\n",
        "  # Remove boxes based on IoU threshold (to prevent multiple detections of same object)\n",
        "  remaining_idx = torchvision.ops.nms(boxes=pred['boxes'],\n",
        "                      scores=pred['scores'],\n",
        "                      iou_threshold=iou_threshold)\n",
        "\n",
        "  boxes = []\n",
        "  labels = []\n",
        "  for idx in remaining_idx:\n",
        "    if pred[\"scores\"][idx] > score_threshold:\n",
        "      boxes.append(pred[\"boxes\"][idx])\n",
        "      labels.append(f\"{class_names[pred['labels'][idx]]}: {round(pred['scores'][idx].item() * 100, 1)}%\")\n",
        "  if boxes:\n",
        "    boxes = torch.stack(boxes)\n",
        "    img = torchvision.utils.draw_bounding_boxes(img,\n",
        "                                  boxes,\n",
        "                                  labels,\n",
        "                                  width=3,\n",
        "                                  font=\"16020_FUTURAM.ttf\",\n",
        "                                  font_size=int(0.025*average)\n",
        "                                  )\n",
        "  return img.permute(1,2,0).numpy() # Gradio accepts numpy nd array as output to convert to an image\n",
        "\n",
        "# Gradio interface\n",
        "\n",
        "title = \"Trash Object Detector ðŸ—‘ï¸\"\n",
        "description = \"A Faster R-CNN model that detects trash objects from [60 classes](https://github.com/purplelord2003/Object-Detection-Model/raw/main/Demo%20preparation/class_names.txt). Try to adjust [IoU threshold](https://learnopencv.com/non-maximum-suppression-theory-and-implementation-in-pytorch/) to be lower if multiple detections of the same object detected. Try to adjust score threshold to be lower if desired object not detected. Examples are defaulted at 0.5 IoU threshold and 0.5 scores threshold, feel free to adjust them and observe the changes in detections!\"\n",
        "article = \"Created at [Trash Object Detection Model notebook](https://github.com/purplelord2003/Object-Detection-Model/blob/main/Jupyter%20Notebooks/Trash_Object_Detection_Model.ipynb).\"\n",
        "\n",
        "# Create examples list\n",
        "example_list = [[\"examples/\" + example] for example in os.listdir(\"examples\")]\n",
        "\n",
        "inputs = [\n",
        "    gr.Image(type=\"pil\", label=\"Input Image\"),\n",
        "    gr.Slider(minimum=0, maximum=1, value=0.5, step=0.01, label=\"Intersection over Union (IoU) Threshold\"),\n",
        "    gr.Slider(minimum=0, maximum=1, value=0.5, step=0.01, label=\"Score Threshold\")\n",
        "]\n",
        "\n",
        "outputs = [\n",
        "    gr.Image(type=\"numpy\", label=\"Output Image\")\n",
        "]\n",
        "\n",
        "demo = gr.Interface(\n",
        "    fn=predict,\n",
        "    inputs=inputs,\n",
        "    examples=example_list,\n",
        "    outputs=outputs,\n",
        "    title=title,\n",
        "    description=description,\n",
        "    article=article\n",
        ")\n",
        "\n",
        "# Launch the app\n",
        "demo.launch()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get examples for demo\n",
        "!wget https://github.com/purplelord2003/Object-Detection-Model/raw/main/Demo%20preparation/Example%20Pictures%20for%20demo/Pictures.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZElEreB7GcY",
        "outputId": "9f030a2d-4e20-481d-afc2-69f87beaebff"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-02-06 10:22:13--  https://github.com/purplelord2003/Object-Detection-Model/raw/main/Demo%20preparation/Example%20Pictures%20for%20demo/Pictures.zip\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://media.githubusercontent.com/media/purplelord2003/Object-Detection-Model/main/Demo%20preparation/Example%20Pictures%20for%20demo/Pictures.zip [following]\n",
            "--2024-02-06 10:22:13--  https://media.githubusercontent.com/media/purplelord2003/Object-Detection-Model/main/Demo%20preparation/Example%20Pictures%20for%20demo/Pictures.zip\n",
            "Resolving media.githubusercontent.com (media.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to media.githubusercontent.com (media.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3028655 (2.9M) [application/zip]\n",
            "Saving to: â€˜Pictures.zipâ€™\n",
            "\n",
            "Pictures.zip        100%[===================>]   2.89M  --.-KB/s    in 0.09s   \n",
            "\n",
            "2024-02-06 10:22:14 (32.5 MB/s) - â€˜Pictures.zipâ€™ saved [3028655/3028655]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from zipfile import ZipFile\n",
        "\n",
        "with ZipFile(\"Pictures.zip\", \"r\") as zip_ref:\n",
        "  zip_ref.extractall(\"demos/trash_detector/examples\")"
      ],
      "metadata": {
        "id": "dnu89aZ__zOz"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf demos/trash_detector/examples/__MACOSX"
      ],
      "metadata": {
        "id": "mgDfPFTc42ZU"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm Pictures.zip"
      ],
      "metadata": {
        "id": "_-ORtuFI_6i9"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JByvfaJaJBG0",
        "outputId": "bf4231b1-c92a-4979-fda4-ffae0f4494e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-02-06 10:22:14--  https://ttfonts.net/sfonts/1/16020_FUTURAM.ttf\n",
            "Resolving ttfonts.net (ttfonts.net)... 31.207.45.27\n",
            "Connecting to ttfonts.net (ttfonts.net)|31.207.45.27|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 38764 (38K) [application/octet-stream]\n",
            "Saving to: â€˜demos/trash_detector/16020_FUTURAM.ttfâ€™\n",
            "\n",
            "16020_FUTURAM.ttf   100%[===================>]  37.86K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2024-02-06 10:22:15 (952 KB/s) - â€˜demos/trash_detector/16020_FUTURAM.ttfâ€™ saved [38764/38764]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Get a font for our labels to be written in\n",
        "!wget -P demos/trash_detector/ https://ttfonts.net/sfonts/1/16020_FUTURAM.ttf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Zip folder but exclude certain files\n",
        "!cd demos/trash_detector && zip -r ../trash_detector.zip * -x \"*.pyc\" \"*.ipynb\" \"*__pycache__*\" \"*ipynb_checkpoints*\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AtO_NIsAPV7c",
        "outputId": "86d96c22-d941-4283-835c-2f601d6e6a5f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: 16020_FUTURAM.ttf (deflated 34%)\n",
            "  adding: app.py (deflated 56%)\n",
            "  adding: class_names.txt (deflated 52%)\n",
            "  adding: examples/ (stored 0%)\n",
            "  adding: examples/3.jpg (deflated 0%)\n",
            "  adding: examples/1.jpg (deflated 0%)\n",
            "  adding: examples/2.jpg (deflated 0%)\n",
            "  adding: fasterrcnn_resnet50_5_epochs_unaugmented.pth (deflated 7%)\n",
            "  adding: model.py (deflated 50%)\n",
            "  adding: requirements.txt (deflated 8%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"demos/trash_detector.zip\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "tnuq2Jq5PgJ7",
        "outputId": "3b62bd0e-97a7-4f37-c0b2-14b886eb0b00"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_3ef90401-1f6f-4a15-84c6-cd7869683890\", \"trash_detector.zip\", 165256419)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
